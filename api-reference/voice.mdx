---
title: "Voice API"
sidebarTitle: "Overview"
description: "API reference for real-time voice transcription and translation with the DeepL Voice API."
public: true
---

The DeepL Voice API provides real-time voice transcription and translation services. The API is designed to be highly available, low latency, and easy for developers to integrate into their applications.

<Info>
  The Voice API is currently available to select DeepL API Pro customers only. Contact your DeepL representative for access.
</Info>

## Overview

The Voice API provides a way to open a streaming connection to DeepL Voice streaming endpoints. With each streaming connection, you can:

* Send a single audio stream
* Receive transcription in the source language
* Receive translations in multiple target languages simultaneously

The API uses a two-step flow:
1. **Request a streaming URL** via REST API
2. **Stream audio and receive transcriptions** via WebSocket

## Supported Languages

### Source Languages

As of July 2025, the following source languages are supported for voice input:

* Chinese (Mandarin)
* Dutch
* English
* French
* German
* Indonesian
* Italian
* Japanese
* Korean
* Polish
* Portuguese
* Romanian
* Russian
* Spanish
* Swedish
* Turkish
* Ukrainian

Several new additions are planned for later in the year.

### Target Languages

All source languages can be translated to all [DeepL Translate supported languages](/docs/getting-started/supported-languages#translation-target-languages), including:

Arabic, Bulgarian, Chinese (simplified), Chinese (traditional), Czech, Danish, Dutch, English (American), English (British), Estonian, Finnish, French, German, Greek, Hebrew, Hungarian, Indonesian, Italian, Japanese, Korean, Latvian, Lithuanian, Norwegian, Polish, Portuguese, Portuguese (Brazilian), Romanian, Russian, Slovak, Slovenian, Spanish, Swedish, Turkish, Ukrainian, and Vietnamese.

## Two-Step API Flow

The Voice API uses a two-step flow to initiate streaming:

### Step 1: Request Session and Stream URL (REST)

Make a POST request to obtain an ephemeral streaming URL and authentication token:

```http
POST https://api.deepl.com/v1/voice/realtime
```

This step handles:
* Authentication and authorization
* Main configuration options (audio format, languages, glossaries, etc.)

See the [Get Streaming URL](/api-reference/voice/get-streaming-url) documentation for details.

### Step 2: Streaming Audio and Text (WebSocket)

Use the received URL to establish a WebSocket connection for:
* Sending audio data
* Receiving transcriptions and translations in real-time

See the [WebSocket Streaming](/api-reference/voice/websocket-streaming) documentation for details.

## Limitations and Constraints

* Maximum 5 target languages per stream
* Maximum streaming connection duration: 3 hours
* Audio chunk size: should not exceed 100 KByte or 1 second duration
* Recommended chunk duration: 50-250ms for low latency
* Audio stream speed: maximum 2x real-time
* Request body size: no specified limit for streaming (differs from text translation)

## Getting Started

To start using the Voice API:

1. Ensure you have a DeepL API Pro account with Voice API access
2. Review the [Get Streaming URL](/api-reference/voice/get-streaming-url) documentation
3. Review the [WebSocket Streaming](/api-reference/voice/websocket-streaming) documentation
4. Choose your audio format and configuration
5. Implement the two-step flow in your application

<Info>
  For privacy and security, streaming URLs are ephemeral and valid for one-time use only. Once a WebSocket connection is established, you must send audio data within the specified timeout period to prevent connection closure.
</Info>
